{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "committed-mason",
   "metadata": {},
   "source": [
    "# 목표\n",
    "\n",
    "- 텍스트 데이터를 머신러닝 입출력용 수치데이터로 변환하는 과정\n",
    "- RNN특징 이해하고 시퀀셜한 데이터를 다루는 방법이해\n",
    "- 1-D CNN 으로 텍스트 처리\n",
    "- IMDB와 네이버 영화리뷰 데이터셋을 이용한 영화리뷰 감성분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-tolerance",
   "metadata": {},
   "source": [
    "## 감성분석\n",
    "### 텍스트 데이터만이 가지고 있는 정보적 특성과 가치?\n",
    "\n",
    "### 감성분석 등 텍스트 분류 모델이 다른 데이터 분석 업무에 어떤 점에서 도움을 주는지\n",
    "### 텍스트 데이터 분석의 기술적 어려움\n",
    "### 텍스트 분류 작업을 하는데 딥러닝이 적용되면?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "usual-september",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exciting-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터로부터 사전을 만들기 위해 모든 문장을 단어 단위로 쪼갠 후에 파이썬 딕셔너리 자료구조로 표현\n",
    "index_to_word = {}\n",
    "# 단어들을 하나씩 채운다\n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-marketplace",
   "metadata": {},
   "source": [
    "10개의 딕셔너리가 만들어졌다.\n",
    "\n",
    "텍스트를 숫자로 바꾸려면 딕셔너리가 {텍스트 : 인덱스} 구조여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "laughing-clock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rising-smart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀐다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surprised-technician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터를 숫자로 바꿔서 표현\n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beneficial-wellington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "veterinary-charlotte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afraid-highlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-harris",
   "metadata": {},
   "source": [
    "## 텍스트데이터의 특징\n",
    "\n",
    "단어와 그 단어의 의미를 나타내는 벡터를 짝짓는 것이 목적\n",
    "\n",
    "단어의 의미를 나타내는 벡터를 훈련 가능한 파라미터로 놓고, 이를 딥러닝을 통해 학습을 시킨 후 최적화를 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "federal-pierre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.04236231  0.03135984 -0.00377493  0.04759136]\n",
      "  [ 0.02938828  0.02408684 -0.01288877 -0.01722717]\n",
      "  [-0.01992481 -0.00639917  0.03488899  0.04269841]\n",
      "  [ 0.02980513  0.00886213 -0.022656    0.02879627]\n",
      "  [-0.01570108  0.0003347  -0.04740087  0.03779669]]\n",
      "\n",
      " [[ 0.04236231  0.03135984 -0.00377493  0.04759136]\n",
      "  [ 0.02938828  0.02408684 -0.01288877 -0.01722717]\n",
      "  [-0.0148233   0.01551263 -0.01815857 -0.03636484]\n",
      "  [ 0.01068026 -0.02750915 -0.02501738  0.01150167]\n",
      "  [-0.01570108  0.0003347  -0.04740087  0.03779669]]\n",
      "\n",
      " [[ 0.04236231  0.03135984 -0.00377493  0.04759136]\n",
      "  [-0.03724253 -0.048632    0.00829121  0.00377251]\n",
      "  [ 0.02938828  0.02408684 -0.01288877 -0.01722717]\n",
      "  [-0.01992481 -0.00639917  0.03488899  0.04269841]\n",
      "  [-0.03086872 -0.04725627 -0.03738198 -0.03193387]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Embedding layer 를 활용하여 텍스트 데이터를 워드벡터 텐서 형태로 다시 표현\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-prize",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
